{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 5 - Deep learning for Human Activity Recognition with inertial sensors. \n",
    "\n",
    "#### :: *오 영민*\n",
    "\n",
    "## <u>강의 내용 정리</u>\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    ": IoT의 확산으로 여러 사물에게 센서가 달려, 인간에의 Interactive한 정보들이 쌓여간다. 이 번 강연은 Wearable 스마트 기기들을 통해 얻어지는 인간의 움직임을 연구하는데에 집중 할 것이다. ( 업계에 Dominant한 Paper는 아직 없으며, 다른 분야의 방법론을 차용해서 사용하고 있다.) 옛날 부터 여러 방법으로 사람의 움직임을 간소화하여 이해 하려는 시도가 있었다. (1973년도 visual perceptron 방법론 예) 이런 정보들을 보고, 사람은 그 행동이 뭔지 꽤 높은 정확도로 맞출 수 있었다. 이 후, 모션인식을 연구하기 위해서, 여러 장비들이 발명 되었다. 그러나 이들은 매우 비쌌고, 이로 얻을 수 있는 것은 일반론적인 내용에 관한 인사이트에 머물렀다. 현재는 모두가 가지고 있는 스마트폰에도, 9개 채널 종류의 시그널 데이터를 얻을 수 있는 센서가 부착되어 있다. ( 관성 센서, Neofect 또한 이 센서를 재활치료용 글러브에 부착하여, 연구와 사업을 진행하고 있다고 한다.)\n",
    "\n",
    "##### 관련된 Deep learning Algorithm (이 부분에 거의 40분을 소요)\n",
    "\n",
    "**CNN** - Convolution filter를 통과 시켜, 특징값을 추출 하고, 차원을 축소 시켜, 패턴을 더 잘 찾을 수 있도록 학습 시킨다. \n",
    "\n",
    "**RNN** - FFNN의 구조에서 중간의 Hidden state 의 vector 를 다음 타임스텝에 반영 하여 연산 하면서, 시계열 데이터를 처리 할 수 있게 한다. \n",
    "\n",
    "**LSTM** - RNN이 가지는 Long-Term Dependency 를 극복하기 위해서 발명된 알고리즘, Gredient가 시간에 따라 더 잘 흘러 가게 한다. \n",
    "\n",
    "### 2. Main Papers\n",
    "\n",
    "#### Dataset  \n",
    "\n",
    "> **Opportunity** ; IMU(Inertial Measurement Units, with 7 or 9 sensors) \n",
    ">\n",
    "> **Body-worn inertial Sensors** \n",
    ">\n",
    "> :: 두 데이터 셋은 기본적으로는 비슷하고, 라벨에 포함된 행동에 다소 차이점 이있다. Opportunity에 더 많은 채널의 sensor가 있기 때문에  더 많이 사용된다고 한다. \n",
    "\n",
    "#### Activity Recognition`s topics \n",
    "\n",
    "> 1. Common Research ; Intra-class Variability / Similarity , Null-class Problem \n",
    ">\n",
    "> 2. Specific to Human Activity Recognition ; Definition and diversity of Physical Acitivity\n",
    ">\n",
    ">    ( 어려운 점 :  Class Imbalance, Ground Truth Annotation, Data Collection & experiment Designing)\n",
    "\n",
    "#### Deep Learning fo Sensor-based Activity Recognition: A survey \n",
    "\n",
    "Modality : Body-worn, Object, Ambient, Hybrid \n",
    "\n",
    "Models : DNN, CNN, RNN, DBN/RBM, SAE, Hybrid(Combination of deep learning models)\n",
    "\n",
    "분석 흐름 ; Signal(INPUT) -> Feature extraction -> Model training -> Model training -> Activity detected\n",
    "\n",
    " Datasets : 19가지의 데이터를 사용해 연구진행 (위의 두 데이터셋을 포함, UCI smartphone(가장 common한 데이터))\n",
    "\n",
    "가장 좋았던 모델 : Bi-directional LSTM-S ( metric: 92.70 )\n",
    "\n",
    "#### Deep Convolutional and LSTM Recurrent Neural Networks for Multimodel wearable Activity Recognition \n",
    "\n",
    "Temporal Covolution 적용 ; 시간을 고려한 convolutinal network\n",
    "\n",
    "> $a_j^{l+1}(\\tau) = \\sigma(b_j^l + \\sum_{f=1}^{F^l}k_{jf}^l(\\tau)*a_f^l(\\tau)) = \\sigma( b_j^l + \\sum_{f=1}^{F^l}[\\sum_{p=1}^{p^i}K^l_{jf}(p)a_f^l(\\tau- p)  ]  )$ \n",
    "\n",
    "모델 구조 ; INPUT -> Convolution x 5 -> Dense layer x 2 -> Softmax\n",
    "\n",
    "행동간의 차이점과 유사점을 한눈에 볼 수 있다. \n",
    "\n",
    "* Opportunity datasets에 대하여, DeepConvLSTM이 가장 좋은 성능을 보였다. \n",
    "* 데이터 내에서, 여러 센서를 한번에 학습할 때, 성능이 더 좋았다.(F1score : 0.864)\n",
    "\n",
    "#### Deep, Convolutional and Recurrent Models for HAR using Wearables \n",
    "\n",
    ":: LSTM의 결과를 Convolution layer 에 통과 시키는 구조 ; 실시간으로 분석은 어렵다는 단점이 있다. \n",
    "\n",
    "#### UniMiB SHAR: A dataset for JAR using acceleration Data from Smartphones\n",
    "\n",
    ":: Dataset이 일상적인 자료라서 큰 파급 효과를 기대한다.\n",
    "\n",
    ":: 넘어지는 것 만 다룬다. Falling backward/forward /sideward, Specific fail\n",
    "\n",
    "### 3. Additional Papers\n",
    "\n",
    "**실습시 추천 Datasets** ;\n",
    "\n",
    "UCF101, THUMOS-14, THUMOS-15\n",
    "\n",
    "**한 번 읽어 볼 것** ;\n",
    "\n",
    "Dense Labeling with fully Convolutional Neural Networks - Sliding window 적용\n",
    "\n",
    "Convolutional Deep Belife Networks fo scalable Unsupervised Learning of Hierarchical Representations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
