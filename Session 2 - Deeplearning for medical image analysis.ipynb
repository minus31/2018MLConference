# Session 2 - Deep learning for Medical Image 

#### :: *황 상흠*

----------

## <u>강의 내용 정리</u>

### 1. 기존의 병리학과 영상의학

> 32% 의 암이 Momography(4000 ,4000 이미지 4장) 검사에서 오분류된다. 
>
> 25%의 가슴 조직 검사에서 병리학적인 견해 불일치가 발생한다. 
>
> 가슴 X-ray사진을 진단하는 정량적인 분류 방법이 부족한 실태이다. 

아직까지 병리학에서는 조직을 추출해 현미경으로 병리학 의사들이 진단을 내린다. Digital화 되어 Scan장비를 이용하여 진단하기 시작한 것은 아주 최근의 일이다. 

이러한 분야에 Deep learning이 적용되면서, 제레미 힐튼교수가 이에 대해 언급한 인터뷰가 화제가 된 적이 있다. 

> "영상의학 전문의 양성을 중단해야한다. 5년 에서 10년 안에 이 모든 기능을 Deeplearning 이 대체하게 될 것 이기 때문이다."
>
>  $\rightarrow$ 이에 대해 연사님은 반은 맞고, 반은 틀렸다고 하신다. 사실 영상의학에서 다루는 것이 특정 질환의 진단에 머물러있지 않고 그 영상을  의사의 역량에 따라 아주 다양하게 해석할 수 있기 때문이다. 하지만 몇 몇 분야에서는 실제로 Deeplearning이 더 잘 기능하기도 한다. 

* 의료 영상으로 할 수 있는 것들 

  > * Mammographic mass classification 
  > * Segmentation lesions in the brain
  > * Leak detection in airway tree Segmentation 
  > * Diabetic retinopathy classification 
  > * Prostate segmentation
  > * Nodule Classification 
  > * Breast cancer metastases detection in lymph nodes 
  > * Skin lesion classification 
  > * Bone supperssion in chest X-ray
  >
  > $\rightarrow$ 여러 분야에서 Deeplearning 기술이 가장 좋은 성능을 내고 있다. 

* 의료 영상 처리의 트렌드 

  > CNN - 지배적으로 이미지처리를 하는 기술은 CNN을 개량한 것 전체의 90% 이상이다. 
  >
  > * 영상종류 (가장 연구가 많이 된 순위, 내림차순)
  >
  >   > MRI
  >   >
  >   > Microscopy
  >   >
  >   > CT
  >   >
  >   > Ultrasound
  >   >
  >   > X-ray
  >   >
  >   > Mammography 
  >   >
  >   > Other
  >   >
  >   > Multiple 
  >   >
  >   > Color fundus Photos
  >
  >   $\rightarrow$ MRI는 Funding이 가장 잘 되는 분양이고 가진 정보가 더 세부적이다. 반면, X-ray, 초음파의 경우 영상이 가진 정보가 많지만 펀딩이 적다. 하지만 이 분야에서 좋은 성능을 낼 수 있다면, 그 혜택을 보는 사람들이 훨씬 많다. 

### 2. 의료 이미지 분석의 개요

기존의 여러 머신러닝 분야에서 처럼 의료 영상 처리도 

Data Acquisition $\rightarrow$ Data Preparation $\rightarrow$ Training 순으로 진행 된다. 

이 때, 의료영상 분야에서 생기는 큰 이슈 두가지가 있다. 

> 1. 이미지의 크기 - 보통 의료 영상의 이미지 크기는 일반적인 이미지보다 훨씬 크다. 20만 X 20만정도 인 영상 부터,  Mammography 의 경우는 4000 X 4000이지만 이런 영상이 4개가 한 쌍이다. 그리고, 진단내용(NLP)도 데이터가 지저분한 경우가 많다.(ex. 병원에 자주오는 환자는 진단내용은 "이전과 같음" 이다. ) 
> 2. 라벨의 모호함 - 위에서 말했듯이, 똑같은 영상을 가지고 의사들의 진단 내용에 차이가 있다. 심지어 같은 의사도 다른 시간대에 진단한 영상에 대해서 차이를 보이는 경우가 많다. 그리고, 분야특성상 비정상의 데이터가 훨씬 작기 때문에 Data imbalance문제도 발생한다. 

### 3. 꼭 읽어야하는 논문 2가지 

1. **Detection of diabetic retinopathy(google , 2016, JAMA )**

   * 이 논문은 **기술 보다 데이터 품질이 중요하다** 라는 사실을 더욱 절실히 느끼게 해준다. 

   * Human error에 취약한 의료 분야를 극복하기 위해서, 큰 회사가 가지는 자본력을 이용했다. 

     > 총 54명의 의사에게 진단 별로 payment를 지급 하였다. - 그래서 한 영상 당 평균 8명의 의사가 진단을 했다. 
     >
     > $\rightarrow$ 심지어, 이 때, 의사에게 저번에 보여줬던 것을 몰래 보여주어서, 그 의사의 **self-consistency**도 수치화 하였다. 

   * **Deeplearning 에서는 Vaildation데이터의 품질이 더 중요하다.** 

     > 이를 위해서, **self-consistency**가 높은 의사 8명을 선발하여, Validation데이터의 진단을 맡겼다. 

     결과적으로 기존의 모든 연구들의 성과를 앞섰고, 이 분야의 영상들은 대게 고정되고, 차이가 적기 때문에  데이터가 아주 많아야 하는 것이 아니라는 것을 알 수 있었다. 

2. **Classification of skin cancer (Stanford, 2017, Nature)**

   피부암의 초기 진단을 위해서, 일반적인 사진으로 피부암을 찾는 것이 목표 이다. 

   이 논문에서는 사진 안에서 병변의 크기가 아주 작은 것을 Detaction하는 것을 극복하였고, 이를 가능케 했던 CNN의 구조가 의미있다.  연사님은 이 구조를 잘 이해해보기를 추천하는 정도로 이 논문의 설명을 간추렸다. 

### 4. Important Topics

* Active Learning - 지금의 모델이 필요한 데이터를 어떻게 더 모을 것인가. 
* Weakly supervised learning  - 어떻게 많은 량의 데이터를 얻을 수 있을까 (양질의 데이터를 포기, 저수준의 label 데이터 수집)
* semi supervised learning  - 어떻게 라벨이 없는 데이터를 잘 활용 할 수 있을까
* class imbalance  - 데이터 imbalance 문제를 어떻게 해결 할 것 인가. 
* Interpretability - Deep learning은 단점인 블랙박스, 설명해주는 것이 적다는 점이 의료에서는 치명적인 단점이다. 



#### Active learning 

잘 라벨드 된 데이터를 많이 모으는 것은 아주 힘들고, 많은 자본을 필요로 한다. 하지만 모델을 만드는데 있어 중요한 것은 데이터의 양이 아니라 데이터의 품질 이다. 이 때 품질은 **데이터의 다양성**을 의미 한다. (**Fine tuning for medical images**)Active learning은 자본의 낭비를 줄이기 위해, pre-trained model( 데이터가 좋다 나쁘다 정도는 구별할 수 있는 모델, with unlabeled data)을 만들고, 지금 모델이 필요로하는 데이터들을( 현재 잘 Detaction 하지 못하는 데이터) 추려내서 확보할 수 있게 하여, 데이터를 수집할 때 드는 비용을 줄일 수 있다. 이런 전략이 내포된  IFT(Incremental Fine-Tuning Random) 방식으로 AUC(Area under the curve, ROC의 면적을 나타냄)를 비교해보면 Colonoscopy frame classification에서는 75%의 데이터 라벨링 비용을 감소 시킬 수 있었고, Polyp detection 에 경우 거의 90%의 비용을 절감할 수 있었다. (**Suggestive annotation**) 또 다른 방법론은 일단 가지고 있는 Annotated 데이터를 가지고 Fully connected network( 왜 Fully connected network를 사용해야하는지는 언급 하셨고, 내부의 구조또한 언급이 없었다.) 를 통과하고 다음 Unlabled data 와 함께 FCN를 다시 통과 하며, Uncertainty 와 representitive 를 구하여, Annotate 가 필요한 데이터를 추출, Annotate를 요청하고 다시 처음으로 돌아가 과정을 반복하며 학습을 진행하는 것이 있다. 

#### Weakly supervised learning 

어떻게 저수준의 라벨을 이용하여 훌륭한 모델을 만들지에 대한 방안이라고 할 수 있겠다. 특히 Segment 문제, 병변 clssification 문제에 있어서 의료 영상의 병변 부위, Segment하고자 하는 부분이 전체 크기에 비해 아주 작은 면적을 차지 하는 것 때문에 그 부분을 다 말해주는 양질의 라벨링이라던가, 혹은 다른 방법을 통해, 이를 극복해야 했다. (**Multiple Instance Learning**) 이미지 하나를 여러개의 instance classes labeled data로 취급한다.  원래 사진(Bag)안에 여러 인스턴스들을 다시 분류한다. (고양이 사진을 주면 그 사진 안에서 고양이가 있는 부분과 없는 부분을 나누는 것을 상상하면 된다.) 실제로 모델의 구조는 공통된 Convolutionanl layers로 쌓고 Feature map의 형태로 Instance를 각자 학습한다. 끝단에서는 모든 feature map을 global pooling(Average or maximum value)  을 하고 FFNN을 통과시켜 여러 차원의 결과 값을 도출한다. (**Self-transfer Learning**) 이와 다르게 Self-transfer Learning에서의 구조는 같은 Convolution layer 를 통과 시키고 첫번째에서는(Stage 1) Classification 결과를 구하고 다음 번에(Stage 2)에서는 같은 과정을 반복하고 Localization 결과를 도출한다. Loss function은 classification 과 localization loss를 앙상블한 값을 쓴다. 실제로 이렇게 했을 때, Tuberculosis detection과 Mammography 처리에서 0.1 상승된 성능을 보여줬다. 부가적으로 병변의 위치를 설명하는데 긍정적인 효과를 가져왔다. 

#### Semi-supervised Learning 

어떻게 labeled되어 있지 않은 데이터를 활용할 수 있을지 고민하는 문제 이다. 처음 시도 되었던 것은 Segment network를 학습시키고 이를  Evaluation  network에 통과 시키고 그 결과를 반영하여 다시 Segment 하는 것을 반복하는 구조였다. 이 후 GAN이 나오면서,  GAN의 Adversary한 구조를 차용하여 적용시켰고, 이에 비교적 적은 Labeled 데이터를 이용해 라벨링이 안되있는 데이터를 십분 활용 할 수있었다.  

#### Class imbalance

의료 분야에 고질적인 문제점 중 하나가 Negative 데이터의 양이 Positive데이터에 비해 아주 극히 작다는 것이다. 이를  극복하기 위해서 아직도 많은 시도가 이루어지고 있다. 가장 보편 적인 방법이 모델을 학습시킬 때, Negative데이터를 먼저 학습 시키고, Positive한 것을 점차적으로 학습시키는 방법이다. 이 방법으로 LUNA(Lung nodule analysis challenge, 2016)에서 가장 높았던 Acuracy는 0.883이었다. 아직 부족한 성능에 이것을 극복하기 위해서도 GAN이 적용되었다. 이는 Raw 데이터를 Latent space에 할당하고 이를, Random vector 대신 Generater에 통과 시켜 abnormal 데이터를 만들고 discriminator가 분류 하게 했다. 의료 분야에서 쓰인 이 GAN모델을 anoGAN이라고 하고, 평균적으로 0.89의 Accuracy를 냈다. 

#### Interpretability

Deeplearning은 결과물에 대한 과정을 보여주지 않는다. 즉, 결과에 대해 정성적인 설명이 없기 때문에, 의료분야 전반에서 역할하기에는  역부족이다. 그래서 이 해석력이라는 문제는 먼저, 어디까지 Deeplearning이 설명해야 하는가 먼저 고민해야 한다. Deeplearning의 interpretability를 구현했던 MDNET을 소개 했다. Bladder pathology image를 받아 진단하는 리포트를 작성하는 모델이다. 인풋데이터는 공통된 Convolution layers를 거치고 만들어진 여러개의 아웃풋을 위한 여러개의 Feature map을 앙상블하여 LSTM with Attention모델에 넣어 문장 vector를 만들고, 인풋이미지에 연결된 진단문이 역시 LSTM with Attention을 통해 학습하여, 이미지로 도출된 시퀸스를 진단문으로 바꿔준다. 

**$\rightarrow$** 의료영상에서 나타나는 여러 문제점이 사실 다른 도메인의 영상처리, 이미지 외의 분야에서도 심심치 않게 마주하게 되는 이슈들이다. 의료영상 특유의 고정적이고, 변화가 적다는 점 등과 영상의 크기를 고려하더라도, 이 강연에서 배운 많은 내용들이 기저환경이 다른 분야에서 많은 쓰임새가 있을 것이라고 느꼈다. 

